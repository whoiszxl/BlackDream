### 多Job工作流实例
1. 创建起始job：`vi start.job`
```bash
type=command
command=echo "start job"
```
2. 创建第一个job：`vi one.job`
```
type=command
dependencies=start
command=echo "one job"
```
3. 创建第二个job：`vi two.job`
```
type=command
dependencies=start
command=echo "two job"
```

4. 创建结尾job：`vi end.job`
```sh
type=command
dependencies=one,two
command=echo "end job"
```

5. 将所有文件打包成zip压缩包
6. 在azkaban web界面中点击`create project`,再点击`upload`,进行执行


### 1.执行Java程序
1. 编写好Java程序，通过main函数执行的方式`maven install`,将jar包放到Linux的目录下。
2. 编写job脚本指定Jar包执行：`vi java.job`
```sh
type=javaprocess
java.class=com.whoiszxl.ExecMain
classpath=/opt/module/azkaban/lib/*
```
3. 打包zip包：`zip execjava.zip java.job`
4. 上传到azkaban执行

### 2.执行hdfs任务
```sh
type=command
command=hadoop fs -mkdir /azkaban
```

### 3.执行MR任务
```sh
type=command
command=hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wordcount/input /wordcount/output
```

### 4.执行Hive脚本
1. 将编写的SQL放到Linux上
```sql
use default;
drop table student;
create table student(id int, name string)
row format delimited fields terminated by '\t';
load data local inpath '/opt/module/datas/student.txt' into table student;
insert overwrite local directory '/opt/module/datas/student'
row format delimited fields terminated by '\t'
select * from student;
```
2. 编写脚本指定SQL命令行执行
```sh
type=command
command=hive -f /opt/module/azkaban/jobs/student.sql
```