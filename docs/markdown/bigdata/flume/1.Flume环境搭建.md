### Flume概念原理
Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。

当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。

Flume在大数据方案中的作用就是`实时读取服务器本地磁盘额数据`，将`数据写入到HDFS,Kafka等`


#### 优点
1. 可以和任意存储进程集成。
2. flume缓冲hdfs接收数据过大的压力。
3. 消息可靠。

#### 组织结构
1. Agent：JVM进程，以事件形式将数据从源头传递到目的地，由Source、Channel、Sink组成。
2. Source：接收数据到Agent的组件，可以处理avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy类型的日志数据。
3. Channel：是source和sink中间的缓冲区，线程安全，支持内存和文件两种缓冲机制。
4. Sink：轮询Channel中事件，批量写入存储或索引系统或发送给另一个Flume Agent，并移除事件。
5. Event：Flume数据传输的基本单元，由可选的header和载有数据的一个byte array构成，Header是容纳了key-value字符串对的HashMap。

#### Flume企业方案
1. 每台机器上布置一台Flume采集服务
2. 每台Flume采集服务再聚合发送到一个Flume服务
3. 总Flume服务再下发到Hdfs等地方


### Flume环境搭建
> 文档地址：http://flume.apache.org/FlumeUserGuide.html
> 下载地址：http://archive.apache.org/dist/flume/

1. 下载Flume安装包：`wget http://archive.apache.org/dist/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz`
2. 解压包并重命名：`tar -zxvf apache-flume-1.9.0-bin.tar.gz -C /opt/module/ && cd /opt/module/ && mv apache-flume-1.9.0-bin/ flume` 
3. 修改配置并增加Java路径：`cd /opt/module/flume/conf && mv flume-env.sh.template flume-env.sh && vi flume-env.sh`
```sh
export JAVA_HOME=/opt/module/jdk1.8.0_144
```


### 实操：实时读取本地文件到HDFS
1. 创建flume配置文件：`vi flume-dir-to-hdfs.conf`
```conf
a3.sources = r3
a3.sinks = k3
a3.channels = c3


; #1.通过执行命令的方式(三选一)
; a1.sources.r1.type = netcat
; a1.sources.r1.bind = localhost
; a1.sources.r1.port = 44444

; #2.通过tail命令的方法(三选一)
; a2.sources.r2.type = exec
; a2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log
; a2.sources.r2.shell = /bin/bash -c

#3.通过监听目录的方式
a3.sources.r3.type = spooldir
a3.sources.r3.spoolDir = /opt/module/flume/upload
a3.sources.r3.fileSuffix = .COMPLETED
a3.sources.r3.fileHeader = true
#忽略所有以.tmp结尾的文件，不上传
a3.sources.r3.ignorePattern = ([^ ]*\.tmp)

#Describe the sink
a3.sinks.k3.type = hdfs
a3.sinks.k3.hdfs.path = hdfs://hadoop001:9000/flume/upload/%Y%m%d/%H
#上传文件的前缀
a3.sinks.k3.hdfs.filePrefix = upload-
#是否按照时间滚动文件夹
a3.sinks.k3.hdfs.round = true
#多少时间单位创建一个新的文件夹
a3.sinks.k3.hdfs.roundValue = 1
#重新定义时间单位
a3.sinks.k3.hdfs.roundUnit = hour
#是否使用本地时间戳
a3.sinks.k3.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a3.sinks.k3.hdfs.batchSize = 100
#设置文件类型，可支持压缩
a3.sinks.k3.hdfs.fileType = DataStream
#多久生成一个新的文件
a3.sinks.k3.hdfs.rollInterval = 60
#设置每个文件的滚动大小大概是128M
a3.sinks.k3.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a3.sinks.k3.hdfs.rollCount = 0

#Use a channel which buffers events in memory
a3.channels.c3.type = memory
a3.channels.c3.capacity = 1000
a3.channels.c3.transactionCapacity = 100

#Bind the source and sink to the channel
a3.sources.r3.channels = c3
a3.sinks.k3.channel = c3
```

2. 启动命令：`bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-dir-to-hdfs.conf`
3. 往`/opt/module/flume/upload`写入数据就会更新数据到HDFS

### 实操：多数据源汇总案例
需求：hadoop002和hadoop001分别监控文件`/opt/module/hello.log`和某个端口的数据流，并发送到hadoop003机器以控制台打印。

1. 分发flume包到其他机器：`xsync /opt/module/flume`
2. 在三台机器下创建目录：`mkdir /opt/module/flume/job/group3`
3. 在Hadoop002下group3目录创建文件：`vim flume1-logger-flume.conf`
```conf
#Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

#Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /opt/module/hello.log
a1.sources.r1.shell = /bin/bash -c

#Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop003
a1.sinks.k1.port = 4141

#Describe the channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

#Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

4. 在Hadoop001下group3目录创建文件：`vi flume2-netcat-flume.conf`
```conf
#Name the components on this agent
a2.sources = r1
a2.sinks = k1
a2.channels = c1

#Describe/configure the source
a2.sources.r1.type = netcat
a2.sources.r1.bind = hadoop001
a2.sources.r1.port = 44444

#Describe the sink
a2.sinks.k1.type = avro
a2.sinks.k1.hostname = hadoop003
a2.sinks.k1.port = 4141

#Use a channel which buffers events in memory
a2.channels.c1.type = memory
a2.channels.c1.capacity = 1000
a2.channels.c1.transactionCapacity = 100

#Bind the source and sink to the channel
a2.sources.r1.channels = c1
a2.sinks.k1.channel = c1
```

5. 在Hadoop003下group3目录创建文件：`vi flume3-flume-logger.conf`
```conf
#Name the components on this agent
a3.sources = r1
a3.sinks = k1
a3.channels = c1

#Describe/configure the source
a3.sources.r1.type = avro
a3.sources.r1.bind = hadoop003
a3.sources.r1.port = 4141

#Describe the sink
a3.sinks.k1.type = logger

#Describe the channel
a3.channels.c1.type = memory
a3.channels.c1.capacity = 1000
a3.channels.c1.transactionCapacity = 100

#Bind the source and sink to the channel
a3.sources.r1.channels = c1
a3.sinks.k1.channel = c1
```

6. 分别执行对应命令
```s
./bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console

./bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group3/flume2-netcat-flume.conf

./bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group3/flume1-logger-flume.conf
```

7. 在hadoop001和hadoop002机器分别`telnet hadoop102 44444`和`echo 'hello wwwww' > /opt/module/hello.log`,hadoop003便能够接收到消息。