## Hadoop单机环境搭建

### 初始环境准备
1. 运行环境： 三台CentOS 7.4内网互通的Linux机器 hadoop-2.7.2 jdk-8u171-linux-x64
2. 创建新用户并赋予root权限，分别为 zxl,zxl,zxl
```shell
# 创建过程
useradd zxl
passwd zxl
vi /etc/sudoers # 增加一行 zxl    ALL=(ALL)       ALL
su zxl
sudo mkdir /opt/software/ /opt/module/
sudo chown -R zxl:zxl /opt/software/ /opt/module/
```
3. 配置Java运行环境
```shell
# 解压
tar -zxvf software/jdk-8u171-linux-x64.tar.gz -C module/

# 配置环境变量
sudo vim /etc/profile
# 末尾添加JDK路径
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_144
export PATH=$PATH:$JAVA_HOME/bin

# 刷新并验证是否生效
source /etc/profile && java -version
```
1. 关闭防火墙（如果是云服务器则需要关闭安全组，处于同一个内网则不需要）
```shell
systemctl status firewalld.service #防火墙状态
systemctl stop firewalld.service   #停止firewall
systemctl disable firewalld.service #开机禁用防火墙自启
```

1. 配置主机名
> 如果是云服务器，配置本地IP的时候需要配置内网地址，外网才能访问
```bash
sudo vim /etc/hosts

# hadoop001
192.168.1.1 hadoop001
192.168.1.2 hadoop002
192.168.1.3 hadoop003

# hadoop002
192.168.1.1 hadoop001
192.168.1.2 hadoop002
192.168.1.3 hadoop003

# hadoop003
192.168.1.1 hadoop001
192.168.1.2 hadoop002
192.168.1.3 hadoop003
```

### Hadoop软件安装
> 软件下载地址： https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/

1. 解压：`tar -zxvf software/hadoop-2.7.2.tar.gz -C module/`
2. 修改配置添加环境变量：`sudo vim /etc/profile`
```bash
##HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```
3. 刷新并验证是否生效：`source /etc/profile && hadoop version`


### Hadoop本地方式运行
> 测试官方WordCount案例

1. 创建文件夹并创建需要计数的文件：`cd /opt/module/hadoop-2.7.2 && mkdir wcinput && cd wcinput && touch wc.txt && vim wc.txt`
2. 运行案例程序：`hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput`



### Hadoop伪分布运行
1. 修改`hadoop-env.sh`文件
```bash
export JAVA_HOME=/opt/module/jdk1.8.0_171
```

2. 修改`core-site.xml`文件
```xml
<!-- 指定HDFS中NameNode的地址 -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop001:9000</value>
</property>

<!-- 指定Hadoop运行时产生文件的存储目录 -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>
```

3. 修改`hdfs-site.xml`文件
```xml
<property>
	<name>dfs.replication</name>
	<value>1</value>
</property>
```

4. 格式化NameNode：`hdfs namenode -format` 第一次启动时需要格式化，以后如果还要格式化必须删除data文件夹，否则再次启动namenode将失败,因为格式化时会产生新的集群id。
5. 启动namenode和datanode: `hadoop-daemon.sh start namenode && hadoop-daemon.sh start datanode`
6. `jps`命令查看是否启动成功:
```
20257 DataNode
20177 NameNode
20328 Jps
```
7. web端进行查看：`http://hadoop001:50070`
8. 操作集群
```shell
hadoop fs -mkdir -p /user/zxl/input # 递归创建文件夹
hadoop fs -put wcinput/wc.txt /user/zxl/input # 上传需要计算的文件
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/zxl/input /user/zxl/output # 开始计算
hadoop fs -cat /user/zxl/output/* # 输出hdfs上统计后的结果
```

9. 配置yarn文件：`vim etc/hadoop/yarn-env.sh`
```bash
export JAVA_HOME=/opt/module/jdk1.8.0_144
```

10. 配置`vim etc/hadoop/yarn-site.xml`
```xml
<!-- Reducer获取数据的方式 -->
<property>
 	<name>yarn.nodemanager.aux-services</name>
 	<value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop001</value>
</property>
```

11. 配置`vim etc/hadoop/mapred-env.sh`
```bash
export JAVA_HOME=/opt/module/jdk1.8.0_144
```

12.  配置：`mapred-site.xml` （修改`mapred-site.xml.template`而来）
```xml
<!-- 指定MR运行在YARN上 -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
```

13.  启动ResourceManager和NodeManager： `yarn-daemon.sh start resourcemanager && yarn-daemon.sh start nodemanager`,得到如下结果：
```
20257 DataNode
20177 NameNode
20587 ResourceManager
20684 Jps
20637 NodeManager
```

14. 操作集群
```bash
hadoop fs -rm -r /user/zxl/output # 删除结果文件夹
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/zxl/input /user/zxl/output # 开始计算
hadoop fs -cat /user/zxl/output/* # 输出hdfs上统计后的结果
```

15. 配置历史服务器，修改文件：`mapred-site.xml`
```xml
<!-- 历史服务器端地址 -->
<property>
<name>mapreduce.jobhistory.address</name>
<value>hadoop001:10020</value>
</property>
<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop001:19888</value>
</property>
```

16. 启动并查看是否成功：`mr-jobhistory-daemon.sh start historyserver && jps`, web服务访问：`http://hadoop001:19888/jobhistory`
17. 开启日志聚合，将日志上传到HDFS可以在web服务中直接访问日志, `vim etc/hadoop/yarn-site.xml`
```xml
<!-- 日志聚集功能使能 -->
<property>
	<name>yarn.log-aggregation-enable</name>
	<value>true</value>
</property>

<!-- 日志保留时间设置7天 -->
<property>
	<name>yarn.log-aggregation.retain-seconds</name>
	<value>604800</value>
</property>
```
18. 重启NodeManager 、ResourceManager和HistoryManager：`yarn-daemon.sh stop resourcemanager && yarn-daemon.sh stop nodemanager && mr-jobhistory-daemon.sh stop historyserver`, `yarn-daemon.sh start resourcemanager && yarn-daemon.sh start nodemanager && mr-jobhistory-daemon.sh start historyserver`