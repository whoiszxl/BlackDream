## Hadoop集群环境搭建

### Linux配置免密登录
1. 在三台云服务器上执行命令生成密钥对，执行后多次回车：`ssh-keygen`
2. 将本地公钥写入远程机器的 `~/.ssh/authorized_key`
```shell
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop001
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop002
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop003
```
3. 验证登录是否有效
```shell
ssh hadoop002
ssh hadoop003
```

### 集群分发脚本xsync编写
> 底层使用`rsync`命令，其主要用于备份和镜像，速度快，避免复制相同内容和支持符号链接。
> 安装：`yum -y install rsync xinetd`
> rsync和scp区别是速度快，只复制具有差异的文件。
> 基本语法：rsync -av $pdir/$fname $user@$host:$pdir/$fname

代码如下，放入`/usr/local/bin`下，并`chmod +x xsync`
```shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if ((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=1; host<4; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -av $pdir/$fname $user@hadoop00$host:$pdir
done
```


### 集群规划
1. hadoop001: namenode, datanode,          nodemanager
2. hadoop002: datanode,                    nodemanager,resourcemanager
3. hadoop003: secondarynamenode, datanode  nodemanager


### 修改配置文件
1. 修改`core-site.xml`
```xml
<!-- 指定HDFS中NameNode的地址 -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop001:9000</value>
</property>

<!-- 指定Hadoop运行时产生文件的存储目录 -->
<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>
```

2. 修改`hadoop-env.sh`
```sh
export JAVA_HOME=/opt/module/jdk1.8.0_171
```

3. 修改`hdfs-site.xml`
```xml
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>

<!-- 指定Hadoop辅助名称节点主机配置 -->
<property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>hadoop003:50090</value>
</property>
```

4. 修改`yarn-env.sh`
```sh
export JAVA_HOME=/opt/module/jdk1.8.0_171
```

5. 修改`yarn-site.xml`
```xml
<!-- Reducer获取数据的方式 -->
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop002</value>
</property>
```

6. 修改`mapred-env.sh`
```sh
export JAVA_HOME=/opt/module/jdk1.8.0_171
```

7. 修改`mapred-site.xml`
```xml
<!-- 指定MR运行在Yarn上 -->
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```

8. 配置slaves集群节点, 编辑slaves文件，增加配置
```conf
hadoop001
hadoop002
hadoop003
```

9.  分发文件
执行命令：`xsync /opt/module/hadoop-2.7.2/`

### 集群启动

0. 删除data和log数据并格式化namenode: `hdfs namenode -format`
1. 在hadoop001启动hdfs: `start-dfs.sh`
2. 在hadoop002启动yarn: `start-yarn.sh`
3. 最终jps结果：
```
hadoop001
25824 NameNode
26285 Jps
26189 NodeManager
25950 DataNode

hadoop002
26212 ResourceManager
26327 NodeManager
26011 DataNode
26668 Jps

hadoop003
31744 DataNode
32049 Jps
31940 NodeManager
31847 SecondaryNameNode
```

### 集群命令总结
1. 分别启动/停止HDFS组件：`hadoop-daemon.sh start/stop  namenode/datanode/secondarynamenode`
2. 启动/停止YARN: `yarn-daemon.sh start/stop  resourcemanager/nodemanager`
3. 整体启动/停止HDFS（需要配置SSH免密）: `start-dfs.sh   /  stop-dfs.sh`
4. 整体启动/停止YARN（需要配置SSH免密）: `start-yarn.sh  /  stop-yarn.sh`